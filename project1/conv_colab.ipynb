{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.optimizers\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from transformers import AutoImageProcessor, ViTImageProcessor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import datasets\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import TFViTForImageClassification, create_optimizer, TFCvtForImageClassification\n",
    "from transformers import CvtConfig, CvtModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:48.494151100Z",
     "start_time": "2023-11-23T11:46:48.470067200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_image_folder_dataset(root_path):\n",
    "    \"\"\"creates `Dataset` from image folder structure\"\"\"\n",
    "\n",
    "    # get class names by folders names\n",
    "    _CLASS_NAMES = os.listdir(root_path)\n",
    "    # defines `datasets` features`\n",
    "    features = datasets.Features({\n",
    "        \"img\": datasets.Image(),\n",
    "        \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n",
    "    })\n",
    "    # temp list holding datapoints for creation\n",
    "    img_data_files = []\n",
    "    label_data_files = []\n",
    "    # load images into list for creation\n",
    "    for img_class in os.listdir(root_path):\n",
    "        for img in os.listdir(os.path.join(root_path, img_class)):\n",
    "            path_ = os.path.join(root_path, img_class, img)\n",
    "            img_data_files.append(path_)\n",
    "            label_data_files.append(img_class)\n",
    "    # create dataset\n",
    "    ds = datasets.Dataset.from_dict({\"img\": img_data_files, \"label\": label_data_files}, features=features)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_imgs = create_image_folder_dataset(\"train\")\n",
    "img_class_labels = train_imgs.features[\"label\"].names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:48.515224100Z",
     "start_time": "2023-11-23T11:46:48.482109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_id = \"google/vit-base-patch16-224-in21k\"\n",
    "#model_id = \"microsoft/cvt-13\"\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_id)\n",
    "feature_extractor.size = {\"width\":224,\"height\":224}\n",
    "# learn more about data augmentation here: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(1024, 1024),\n",
    "        layers.CenterCrop(900, 900),\n",
    "        layers.experimental.preprocessing.RandomCrop(600, 600),\n",
    "        layers.RandomBrightness(factor=0.2),\n",
    "        layers.RandomContrast(factor=0.2),\n",
    "\n",
    "        layers.Rescaling(1/255),\n",
    "        layers.Resizing(224, 224),\n",
    "        #layers.RandomZoom(height_factor=(0,0.15), width_factor=(0,0.15), fill_mode=\"constant\", ),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "\n",
    "        #layers.RandomRotation(factor=0.2, fill_mode=\"constant\", fill_value=0),\n",
    "\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "data_resizing = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(1024, 1024),\n",
    "        layers.CenterCrop(900, 900),\n",
    "        layers.experimental.preprocessing.RandomCrop(450, 450),\n",
    "        layers.Rescaling(1/255),\n",
    "        layers.Resizing(224, 224),\n",
    "    ],\n",
    "    name=\"data_resizing\",\n",
    ")\n",
    "def load_ben_color(image):\n",
    "    sigmaX=10\n",
    "    image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX) ,-4 ,128)\n",
    "    return image\n",
    "# use keras image data augementation processing\n",
    "def augmentation(examples):\n",
    "\n",
    "    inputs = {\"pixel_values\":[data_augmentation(np.array(load_ben_color(np.array(img)))) for img in examples['img']], \"labels\":examples[\"label\"]}\n",
    "    #inputs[\"pixel_values\"] = np.array(inputs[\"pixel_values\"]).swapaxes(1,3)\n",
    "    #raise Exception(str(tf.reduce_min(inputs[\"pixel_values\"])) + \" \" + str(tf.reduce_max(inputs[\"pixel_values\"])))\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# basic processing (only resizing)\n",
    "def process(examples):\n",
    "    inputs = {\"pixel_values\":[data_resizing(np.array(load_ben_color(np.array(img)))) for img in examples['img']], \"labels\":examples[\"label\"]}\n",
    "    #inputs[\"pixel_values\"] = np.array(inputs[\"pixel_values\"]).swapaxes(1,3)\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:48.656387200Z",
     "start_time": "2023-11-23T11:46:48.515224100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'model = TFViTForImageClassification.from_pretrained(\\n    model_id,\\n    num_labels=len(labels),\\n    id2label={str(i): c for i, c in enumerate(labels)},\\n    label2id={c: str(i) for i, c in enumerate(labels)}\\n)'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = .1\n",
    "train_val_set = train_imgs.train_test_split(test_size=test_size)\n",
    "train_val_set[\"test\"] = train_val_set[\"test\"].with_transform(process)\n",
    "train_val_set[\"train\"] = train_val_set[\"train\"].with_transform(augmentation)\n",
    "#train_val_set[\"train\"] = train_val_set[\"train\"].with_transform(augmentation)\n",
    "\n",
    "from transformers import TFViTForImageClassification\n",
    "\n",
    "labels = train_val_set['train'].features['label'].names\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2, ResNet101V2, ResNet152V2\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# ResNet50 model\n",
    "#resnet_50 = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "resnet_50 = ResNet152V2(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(224, 224, 3))\n",
    "#resnet_50.trainable = False\n",
    "#build the entire model\n",
    "x = resnet_50.output\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "predictions = layers.Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=resnet_50.input, outputs=predictions)\n",
    "for layer in resnet_50.layers:#[:-20]:\n",
    "   layer.trainable = False\n",
    "\"\"\"model = TFViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\"\"\"\n",
    "\n",
    "#model = TFCvtForImageClassification.from_pretrained(\n",
    "#    model_id,\n",
    "#    )\n",
    "#model.classifier = tf.keras.layers.Dense(5)\n",
    "#model.num_labels = 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:50.424036100Z",
     "start_time": "2023-11-23T11:46:48.659397600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mettn\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\arrow_dataset.py:399: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"center_crop_2\" \"                 f\"(type CenterCrop).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} expected 4 inputs, got 276 [Op:StridedSlice] name: data_augmentation/center_crop_2/strided_slice/\n\nCall arguments received by layer \"center_crop_2\" \"                 f\"(type CenterCrop):\n  • inputs=tf.Tensor(shape=(1024, 1024, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m data_collator \u001B[38;5;241m=\u001B[39m DefaultDataCollator(return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# converting our train dataset to tf.data.Dataset\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m tf_train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_val_set\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tf_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpixel_values\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_cols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# converting our test dataset to tf.data.Dataset\u001B[39;00m\n\u001B[0;32m     21\u001B[0m tf_eval_dataset \u001B[38;5;241m=\u001B[39m train_val_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto_tf_dataset(\n\u001B[0;32m     22\u001B[0m     columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpixel_values\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     23\u001B[0m     label_cols\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     24\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     25\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39meval_batch_size,\n\u001B[0;32m     26\u001B[0m     collate_fn\u001B[38;5;241m=\u001B[39mdata_collator)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\arrow_dataset.py:448\u001B[0m, in \u001B[0;36mTensorflowDatasetMixin.to_tf_dataset\u001B[1;34m(self, batch_size, columns, shuffle, collate_fn, drop_remainder, collate_fn_args, label_cols, prefetch, num_workers, num_test_batches)\u001B[0m\n\u001B[0;32m    444\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;66;03m# TODO(Matt, QL): deprecate the retention of label_ids and label\u001B[39;00m\n\u001B[1;32m--> 448\u001B[0m output_signature, columns_to_np_types \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_output_signature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollate_fn_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcols_to_retain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcols_to_retain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdrop_remainder\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_test_batches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_test_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output_signature:\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m columns \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m columns) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m columns:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\arrow_dataset.py:274\u001B[0m, in \u001B[0;36mTensorflowDatasetMixin._get_output_signature\u001B[1;34m(dataset, collate_fn, collate_fn_args, cols_to_retain, batch_size, num_test_batches)\u001B[0m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_test_batches):\n\u001B[0;32m    273\u001B[0m     indices \u001B[38;5;241m=\u001B[39m sample(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dataset)), test_batch_size)\n\u001B[1;32m--> 274\u001B[0m     test_batch \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    275\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cols_to_retain \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    276\u001B[0m         test_batch \u001B[38;5;241m=\u001B[39m {key: value \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m test_batch\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m cols_to_retain}\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\arrow_dataset.py:2795\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2793\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2794\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2795\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\arrow_dataset.py:2780\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2778\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2779\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 2780\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2782\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2783\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\formatting\\formatting.py:629\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    627\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\formatting\\formatting.py:400\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_column(pa_table)\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 400\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\datasets\\formatting\\formatting.py:515\u001B[0m, in \u001B[0;36mCustomFormatter.format_batch\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    513\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_batch(pa_table)\n\u001B[0;32m    514\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_features_decoder\u001B[38;5;241m.\u001B[39mdecode_batch(batch)\n\u001B[1;32m--> 515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 41\u001B[0m, in \u001B[0;36maugmentation\u001B[1;34m(examples)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maugmentation\u001B[39m(examples):\n\u001B[1;32m---> 41\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpixel_values\u001B[39m\u001B[38;5;124m\"\u001B[39m:[data_augmentation(np\u001B[38;5;241m.\u001B[39marray(load_ben_color(np\u001B[38;5;241m.\u001B[39marray(img)))) \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m examples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m]], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m:examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;66;03m#inputs[\"pixel_values\"] = np.array(inputs[\"pixel_values\"]).swapaxes(1,3)\u001B[39;00m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;66;03m#raise Exception(str(tf.reduce_min(inputs[\"pixel_values\"])) + \" \" + str(tf.reduce_max(inputs[\"pixel_values\"])))\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "Cell \u001B[1;32mIn[12], line 41\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maugmentation\u001B[39m(examples):\n\u001B[1;32m---> 41\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpixel_values\u001B[39m\u001B[38;5;124m\"\u001B[39m:[\u001B[43mdata_augmentation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_ben_color\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m examples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m]], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m:examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;66;03m#inputs[\"pixel_values\"] = np.array(inputs[\"pixel_values\"]).swapaxes(1,3)\u001B[39;00m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;66;03m#raise Exception(str(tf.reduce_min(inputs[\"pixel_values\"])) + \" \" + str(tf.reduce_max(inputs[\"pixel_values\"])))\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7208\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7209\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer \"center_crop_2\" \"                 f\"(type CenterCrop).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} expected 4 inputs, got 276 [Op:StridedSlice] name: data_augmentation/center_crop_2/strided_slice/\n\nCall arguments received by layer \"center_crop_2\" \"                 f\"(type CenterCrop):\n  • inputs=tf.Tensor(shape=(1024, 1024, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 5\n",
    "train_batch_size = 64\n",
    "eval_batch_size = 64\n",
    "learning_rate = 0.001\n",
    "weight_decay_rate = 0.01\n",
    "num_warmup_steps = 0\n",
    "output_dir = model_id.split(\"/\")[1]\n",
    "hub_model_id = f'{model_id.split(\"/\")[1]}-eyes'\n",
    "fp16 = True\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = train_val_set[\"train\"].to_tf_dataset(\n",
    "    columns=['pixel_values'],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    "    collate_fn=data_collator)\n",
    "\n",
    "# converting our test dataset to tf.data.Dataset\n",
    "tf_eval_dataset = train_val_set[\"test\"].to_tf_dataset(\n",
    "    columns=['pixel_values'],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=eval_batch_size,\n",
    "    collate_fn=data_collator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:50.853336100Z",
     "start_time": "2023-11-23T11:46:50.426042500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"for x, y in tf_train_dataset:\n",
    "    print(np.array(x[0]).min(), np.array(x[0]).max())\n",
    "    test = np.array(x[0])\n",
    "    print(test.shape)\n",
    "    plt.imshow(x[0])\n",
    "    plt.show()\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:50.854340100Z",
     "start_time": "2023-11-23T11:46:50.853336100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class model_per_epoch(keras.callbacks.Callback):\n",
    "    def __init__(self, model,filepath,save_best_only):\n",
    "        self.filepath=filepath\n",
    "        self.model=model\n",
    "        self.save_best_only=save_best_only\n",
    "        self.lowest_loss=np.inf\n",
    "        self.best_weights=self.model.get_weights()\n",
    "    def on_epoch_end(self,epoch, logs=None):\n",
    "        v_loss=logs.get('val_loss')\n",
    "        if v_loss< self.lowest_loss:\n",
    "            self.lowest_loss =v_loss\n",
    "            self.best_weights=self.model.get_weights()\n",
    "            self.best_epoch=epoch +1\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            name= str(self.best_epoch) +'-' + str(self.lowest_loss)[:str(self.lowest_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save_weights(file_id)\n",
    "        if self.save_best_only==False:\n",
    "            name= str(epoch) +'-' + str(v_loss)[:str(v_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save(file_id)\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.save_best_only == True:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            name= str(self.best_epoch) +'-' + str(self.lowest_loss)[:str(self.lowest_loss).rfind('.')+3] + '.h5'\n",
    "            file_id=os.path.join(self.filepath, name)\n",
    "            self.model.save_weights(file_id)\n",
    "            print(' model is returned with best weights from epoch ', self.best_epoch)\n",
    "\n",
    "save_dir=r''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:46:50.858353500Z",
     "start_time": "2023-11-23T11:46:50.854340100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "]\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(patience=1),\n",
    "           model_per_epoch(model, save_dir, True)]\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\",)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T11:46:50.855343100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    tf_train_dataset.prefetch(20),\n",
    "    validation_data=tf_eval_dataset.prefetch(20),\n",
    "    callbacks=callbacks,\n",
    "    epochs=100,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T11:46:50.856346200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights(\"transformer_weights.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T11:46:50.857350Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
